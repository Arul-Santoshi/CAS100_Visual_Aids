{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgOe3NtB-q2X"
      },
      "source": [
        "# MLB Project - Fine-Tuning Embedding Models for RAG\n",
        "\n",
        "## Project Overview\n",
        "\n",
        "Welcome to the Embedding Fine-Tuning Project! In this project, you'll learn how to **fine-tune an embedding model** to improve retrieval performance in RAG (Retrieval-Augmented Generation) applications.\n",
        "\n",
        "### What are Embedding Models?\n",
        "Embedding models convert text into dense vector representations (embeddings) that capture semantic meaning. They're crucial for:\n",
        "- **Semantic search**: Finding similar documents based on meaning, not just keywords\n",
        "- **RAG systems**: Retrieving relevant context to answer questions\n",
        "- **Clustering**: Grouping similar documents together\n",
        "\n",
        "### Why Fine-Tune Embeddings?\n",
        "Pre-trained embedding models are trained on general knowledge, which limits their effectiveness for domain-specific applications. Fine-tuning on your specific data can significantly boost retrieval performance!\n",
        "\n",
        "### What is Matryoshka Representation Learning?\n",
        "Matryoshka embeddings can be truncated to various dimensions (768 → 512 → 256 → 128 → 64) without significant performance loss. This allows:\n",
        "- **3x less storage** while keeping ~99% performance\n",
        "- **Faster search** with smaller dimensions\n",
        "- **Flexibility** to choose speed vs. accuracy trade-offs\n",
        "\n",
        "### What You'll Learn\n",
        "- How to prepare datasets for embedding fine-tuning\n",
        "- How to evaluate embedding models using information retrieval metrics\n",
        "- How to implement Matryoshka Representation Learning\n",
        "- How to fine-tune embedding models with Sentence Transformers\n",
        "- How to compare performance across different embedding dimensions\n",
        "\n",
        "### Project Structure\n",
        "1. Setup and imports\n",
        "2. Load and prepare the dataset\n",
        "3. Create baseline evaluation\n",
        "4. Define loss function with Matryoshka representation\n",
        "5. Fine-tune the embedding model\n",
        "6. Evaluate and compare results\n",
        "\n",
        "### Dataset: Financial Q&A Pairs\n",
        "We'll use a dataset of financial questions and answers from NVIDIA's SEC filings to create a domain-specific embedding model.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkvDxZKt-q2Y"
      },
      "source": [
        "## Step 1: Setup and Imports\n",
        "\n",
        "First, let's install the required libraries and import them.\n",
        "\n",
        "**Note**: This project requires a GPU for efficient training. Make sure you're running on a GPU-enabled environment (like Colab with GPU runtime)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Fixing package dependencies...\")\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    # Fix fsspec version to match gcsfs requirement\n",
        "    subprocess.check_call([\n",
        "        sys.executable, \"-m\", \"pip\",\n",
        "        \"install\", \"--upgrade\", \"fsspec==2025.3.0\", \"-q\"\n",
        "    ])\n",
        "    print(\"✓ Dependencies fixed!\")\n",
        "except Exception as e:\n",
        "    print(f\"Note: Could not auto-fix dependencies: {e}\")\n",
        "    print(\"This is fine - the notebook will still work!\")"
      ],
      "metadata": {
        "id": "D7YF9bWYQ79n",
        "outputId": "881a5916-bc86-46ee-f2c6-a957c1edb2fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixing package dependencies...\n",
            "✓ Dependencies fixed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "N_raVXQ2-q2Z",
        "outputId": "ffa06e48-54f2-4f09-d98b-f2071f98010b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install required packages (run this cell first!)\n",
        "!pip install \"torch\" tensorboard -q\n",
        "!pip install --upgrade \"sentence-transformers>=3\" \"datasets==2.19.1\" \"transformers==4.41.2\" -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w9Sk_S1i-q2Z",
        "outputId": "b4e98c73-7ab5-42de-f04e-c9db0a164c03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Failed to import transformers.trainer because of the following error (look up to see its traceback):\ncannot import name 'EncoderDecoderCache' from 'transformers' (/usr/local/lib/python3.12/dist-packages/transformers/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1535\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1536\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_peft_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpeft\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPeftModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/peft/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m from .auto import (\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mMODEL_TYPE_TO_PEFT_MODEL_MAPPING\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/peft/auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPeftConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m from .peft_model import (\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mPeftModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMSELoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDynamicCache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEncoderDecoderCache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPreTrainedModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_outputs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuestionAnsweringModelOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequenceClassifierOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTokenClassifierOutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'EncoderDecoderCache' from 'transformers' (/usr/local/lib/python3.12/dist-packages/transformers/__init__.py)",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2569542049.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcatenate_datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSentenceTransformerModelCardData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSentenceTransformerTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInformationRetrievalEvaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequentialEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMatryoshkaLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultipleNegativesRankingLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mexport_static_quantized_openvino_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 15\u001b[0;31m from sentence_transformers.cross_encoder import (\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mCrossEncoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mCrossEncoderModelCardData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/cross_encoder/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mCrossEncoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCrossEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodel_card\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCrossEncoderModelCardData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCrossEncoderTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtraining_args\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCrossEncoderTrainingArguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/cross_encoder/trainer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_args\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCrossEncoderTrainingArguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceEvaluator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequentialEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformerTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_datasets_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/trainer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchSampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConcatDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvalPrediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPreTrainedTokenizerBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainerCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransformers_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_collator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataCollator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1523\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1526\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1535\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   1538\u001b[0m                 \u001b[0;34mf\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;34mf\" traceback):\\n{e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.trainer because of the following error (look up to see its traceback):\ncannot import name 'EncoderDecoderCache' from 'transformers' (/usr/local/lib/python3.12/dist-packages/transformers/__init__.py)"
          ]
        }
      ],
      "source": [
        "# Import all necessary libraries\n",
        "import os\n",
        "import torch\n",
        "import warnings\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "from sentence_transformers import SentenceTransformer, SentenceTransformerModelCardData, SentenceTransformerTrainer\n",
        "from sentence_transformers.evaluation import InformationRetrievalEvaluator, SequentialEvaluator\n",
        "from sentence_transformers.losses import MatryoshkaLoss, MultipleNegativesRankingLoss\n",
        "from sentence_transformers.util import cos_sim\n",
        "from sentence_transformers import SentenceTransformerTrainingArguments\n",
        "from sentence_transformers.training_args import BatchSamplers\n",
        "\n",
        "# Suppress unnecessary warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "print(\"All libraries imported successfully!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGKilY6Y-q2Z"
      },
      "source": [
        "## Step 2: Configuration\n",
        "\n",
        "Let's set up our model configuration and Matryoshka dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaYaJfws-q2Z"
      },
      "outputs": [],
      "source": [
        "# Model configuration\n",
        "MODEL_ID = \"BAAI/bge-base-en-v1.5\"  # Strong base embedding model (109M params, 768 dim)\n",
        "OUTPUT_DIR = \"bge-base-financial-matryoshka\"  # Output directory for fine-tuned model\n",
        "\n",
        "# Matryoshka dimensions (from large to small - this order is important!)\n",
        "MATRYOSHKA_DIMENSIONS = [768, 512, 256, 128, 64]\n",
        "\n",
        "# Training configuration\n",
        "NUM_EPOCHS = 4\n",
        "BATCH_SIZE = 32\n",
        "GRADIENT_ACCUMULATION_STEPS = 16  # Effective batch size = 32 * 16 = 512\n",
        "LEARNING_RATE = 2e-5\n",
        "\n",
        "print(f\"Base Model: {MODEL_ID}\")\n",
        "print(f\"Output Directory: {OUTPUT_DIR}\")\n",
        "print(f\"Matryoshka Dimensions: {MATRYOSHKA_DIMENSIONS}\")\n",
        "print(f\"Training Epochs: {NUM_EPOCHS}\")\n",
        "print(f\"Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"Effective Batch Size: {BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqaXXQ84-q2a"
      },
      "source": [
        "## Step 3: Load and Prepare the Dataset\n",
        "\n",
        "We'll use a financial Q&A dataset with question-context pairs from NVIDIA's SEC filings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYncA5dj-q2a"
      },
      "source": [
        "### 3.1: Load the Dataset\n",
        "\n",
        "**TODO**: Load the financial embedding dataset and prepare it for training.\n",
        "\n",
        "**Dataset format**: Each sample has a `question` and `context` field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGjPWOwp-q2a"
      },
      "outputs": [],
      "source": [
        "print(\"Loading dataset...\")\n",
        "\n",
        "# TODO: Load the dataset from Hugging Face\n",
        "dataset = None  # Replace None with your code\n",
        "\n",
        "print(f\"Dataset loaded with {len(dataset)} samples\")\n",
        "print(f\"\\nDataset structure: {dataset}\")\n",
        "print(f\"\\nDataset features: {dataset.features}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmjkXXTS-q2a"
      },
      "source": [
        "### 3.2: Explore Sample Data\n",
        "\n",
        "Let's look at some examples to understand the question-context pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTolhy7L-q2a"
      },
      "outputs": [],
      "source": [
        "# Display 3 sample question-context pairs\n",
        "print(\"Sample question-context pairs:\\n\")\n",
        "for i in range(3):\n",
        "    sample = dataset[i]\n",
        "    print(f\"Example {i+1}:\")\n",
        "    print(f\"Question: {sample['question']}\")\n",
        "    print(f\"Context: {sample['context'][:200]}...\")  # Show first 200 chars\n",
        "    print(\"-\" * 80)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7h2DF0Nc-q2a"
      },
      "source": [
        "### 3.3: Prepare Dataset for Sentence Transformers\n",
        "\n",
        "Sentence Transformers expects specific column names: `anchor` (query) and `positive` (relevant document).\n",
        "\n",
        "**TODO**: Rename columns and add IDs to the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUJIbgLu-q2a"
      },
      "outputs": [],
      "source": [
        "# TODO: Rename 'question' column to 'anchor'\n",
        "dataset = None  # Replace None with your code\n",
        "\n",
        "# TODO: Rename 'context' column to 'positive'\n",
        "dataset = None  # Replace None with your code\n",
        "\n",
        "# TODO: Add an 'id' column with sequential numbers\n",
        "dataset = None  # Replace None with your code\n",
        "\n",
        "print(\"Dataset prepared!\")\n",
        "print(f\"\\nUpdated columns: {dataset.column_names}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhj0MEvD-q2a"
      },
      "source": [
        "### 3.4: Split the Dataset\n",
        "\n",
        "**TODO**: Split the dataset into train (90%) and test (10%) sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fOaWhDe-q2a"
      },
      "outputs": [],
      "source": [
        "# TODO: Split dataset into train (90%) and test (10%)\n",
        "dataset = None  # Replace None with your code\n",
        "\n",
        "print(\"Dataset split complete!\")\n",
        "print(f\"\\nDataset splits:\")\n",
        "print(f\"Training: {len(dataset['train'])} samples\")\n",
        "print(f\"Test: {len(dataset['test'])} samples\")\n",
        "\n",
        "# Save datasets to disk for later use\n",
        "dataset[\"train\"].to_json(\"train_dataset.json\", orient=\"records\")\n",
        "dataset[\"test\"].to_json(\"test_dataset.json\", orient=\"records\")\n",
        "print(\"\\nDatasets saved to disk!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP9iR8zy-q2b"
      },
      "source": [
        "## Step 4: Create Baseline Evaluation\n",
        "\n",
        "Before fine-tuning, let's evaluate the pre-trained model to establish a baseline.\n",
        "\n",
        "### Understanding Evaluation Metrics\n",
        "\n",
        "We'll use **NDCG@10** (Normalized Discounted Cumulative Gain at 10):\n",
        "- Measures ranking quality (0 to 1, higher is better)\n",
        "- Takes into account the position of relevant documents\n",
        "- @10 means we look at the top 10 retrieved documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNKZ6xrV-q2b"
      },
      "source": [
        "### 4.1: Load the Pre-trained Model\n",
        "\n",
        "**TODO**: Load the base embedding model for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNgYrC6o-q2b"
      },
      "outputs": [],
      "source": [
        "print(\"Loading pre-trained model...\")\n",
        "\n",
        "# TODO: Load the SentenceTransformer model\n",
        "model = None  # Replace None with your code\n",
        "\n",
        "print(f\"Model loaded: {MODEL_ID}\")\n",
        "print(f\"   Embedding dimension: {model.get_sentence_embedding_dimension()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTyv3OzC-q2b"
      },
      "source": [
        "### 4.2: Prepare Evaluation Data\n",
        "\n",
        "For evaluation, we need:\n",
        "- **Corpus**: All documents that could be retrieved (train + test)\n",
        "- **Queries**: Questions from the test set\n",
        "- **Relevant docs**: Mapping of which document is relevant for each query\n",
        "\n",
        "**TODO**: Load the datasets and create the evaluation dictionaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0D4WRVF-q2b"
      },
      "outputs": [],
      "source": [
        "# TODO: Load test dataset from JSON file\n",
        "test_dataset = None  # Replace None with your code\n",
        "\n",
        "# TODO: Load train dataset from JSON file\n",
        "train_dataset = None  # Replace None with your code\n",
        "\n",
        "# TODO: Concatenate train and test to create full corpus\n",
        "corpus_dataset = None  # Replace None with your code\n",
        "\n",
        "# TODO: Create corpus dictionary (id -> document text)\n",
        "corpus = None  # Replace None with your code\n",
        "\n",
        "# TODO: Create queries dictionary (id -> question text)\n",
        "queries = None  # Replace None with your code\n",
        "\n",
        "# Create relevant docs mapping (each query's relevant doc has the same ID)\n",
        "relevant_docs = {}\n",
        "for q_id in queries:\n",
        "    relevant_docs[q_id] = [q_id]  # The relevant doc ID matches the query ID\n",
        "\n",
        "print(\"Evaluation data prepared!\")\n",
        "print(f\"   Corpus size: {len(corpus)} documents\")\n",
        "print(f\"   Queries: {len(queries)} questions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD1tWlcV-q2b"
      },
      "source": [
        "### 4.3: Create Matryoshka Evaluators\n",
        "\n",
        "We'll create an evaluator for each dimension to see how performance changes with embedding size.\n",
        "\n",
        "**TODO**: Create evaluators for each Matryoshka dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-bEKqQo-q2b"
      },
      "outputs": [],
      "source": [
        "matryoshka_evaluators = []\n",
        "\n",
        "# TODO: Create an InformationRetrievalEvaluator for each dimension\n",
        "for dim in MATRYOSHKA_DIMENSIONS:\n",
        "    # TODO: Create evaluator for this dimension\n",
        "    ir_evaluator = None  # Replace None with your code\n",
        "    matryoshka_evaluators.append(ir_evaluator)\n",
        "\n",
        "# TODO: Create a sequential evaluator that runs all evaluators\n",
        "evaluator = None  # Replace None with your code\n",
        "\n",
        "print(f\"Created evaluators for {len(MATRYOSHKA_DIMENSIONS)} dimensions!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xAzN3gD-q2b"
      },
      "source": [
        "### 4.4: Run Baseline Evaluation\n",
        "\n",
        "**TODO**: Evaluate the pre-trained model to establish our baseline.\n",
        "\n",
        "This will take a few minutes as it computes embeddings for all queries and documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGpJy7aq-q2b"
      },
      "outputs": [],
      "source": [
        "print(\"Evaluating baseline model...\\n\")\n",
        "print(\"This may take a few minutes...\\n\")\n",
        "\n",
        "# TODO: Run the evaluator on the model\n",
        "results = None  # Replace None with your code\n",
        "\n",
        "print(\"\\nBaseline evaluation complete!\\n\")\n",
        "print(\"Baseline NDCG@10 scores by dimension:\\n\")\n",
        "\n",
        "# Print NDCG@10 scores for each dimension\n",
        "baseline_scores = {}\n",
        "for dim in MATRYOSHKA_DIMENSIONS:\n",
        "    key = f\"dim_{dim}_cosine_ndcg@10\"\n",
        "    score = results[key]\n",
        "    baseline_scores[dim] = score\n",
        "    print(f\"   dim {dim}: {score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLJygPdj-q2b"
      },
      "source": [
        "## Step 5: Define Loss Function with Matryoshka Representation\n",
        "\n",
        "Now we'll set up our loss function for fine-tuning.\n",
        "\n",
        "### Understanding the Loss Functions\n",
        "\n",
        "1. **MultipleNegativesRankingLoss**: For positive pairs (question, context), treats other samples in the batch as negatives\n",
        "2. **MatryoshkaLoss**: Wraps the loss to train multiple dimensions simultaneously"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT8q7JQx-q2b"
      },
      "source": [
        "### 5.1: Reload Model for Training\n",
        "\n",
        "**TODO**: Load the model with SDPA (Scaled Dot-Product Attention) for efficient training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abrFH5Kh-q2b"
      },
      "outputs": [],
      "source": [
        "print(\"Loading model for fine-tuning...\")\n",
        "\n",
        "# TODO: Load model with SDPA attention and model card data\n",
        "model = None  # Replace None with your code\n",
        "\n",
        "print(\"Model loaded for training!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqU8gNTG-q2c"
      },
      "source": [
        "### 5.2: Initialize Loss Function\n",
        "\n",
        "**TODO**: Create the Matryoshka loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9K7y7z1-q2c"
      },
      "outputs": [],
      "source": [
        "# TODO: Create the inner loss function (MultipleNegativesRankingLoss)\n",
        "inner_train_loss = None  # Replace None with your code\n",
        "\n",
        "# TODO: Wrap with MatryoshkaLoss\n",
        "train_loss = None  # Replace None with your code\n",
        "\n",
        "print(\"Loss function configured!\")\n",
        "print(f\"   Inner loss: {type(inner_train_loss).__name__}\")\n",
        "print(f\"   Matryoshka dimensions: {MATRYOSHKA_DIMENSIONS}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqrEFfF_-q2c"
      },
      "source": [
        "## Step 6: Set Up Training Arguments\n",
        "\n",
        "**TODO**: Configure the training parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQ8jbSBL-q2c"
      },
      "outputs": [],
      "source": [
        "# TODO: Define training arguments\n",
        "args = SentenceTransformerTrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    num_train_epochs=None,                    # TODO\n",
        "    per_device_train_batch_size=None,         # TODO\n",
        "    gradient_accumulation_steps=None,         # TODO\n",
        "    per_device_eval_batch_size=16,\n",
        "    warmup_ratio=0.1,\n",
        "    learning_rate=None,                       # TODO\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    optim=\"adamw_torch_fused\",\n",
        "    tf32=True,\n",
        "    bf16=True,\n",
        "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # Important for MultipleNegativesRankingLoss\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_steps=10,\n",
        "    save_total_limit=3,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_dim_128_cosine_ndcg@10\",  # Optimize for 128 dimensions\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "print(\"Training arguments configured!\")\n",
        "print(f\"\\nTraining configuration:\")\n",
        "print(f\"   Epochs: {args.num_train_epochs}\")\n",
        "print(f\"   Batch size: {args.per_device_train_batch_size}\")\n",
        "print(f\"   Gradient accumulation: {args.gradient_accumulation_steps}\")\n",
        "print(f\"   Effective batch size: {args.per_device_train_batch_size * args.gradient_accumulation_steps}\")\n",
        "print(f\"   Learning rate: {args.learning_rate}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmCA28RY-q2c"
      },
      "source": [
        "## Step 7: Create the Trainer\n",
        "\n",
        "**TODO**: Create the SentenceTransformerTrainer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDljAFhM-q2c"
      },
      "outputs": [],
      "source": [
        "# Reload training dataset\n",
        "train_dataset = load_dataset(\"json\", data_files=\"train_dataset.json\", split=\"train\")\n",
        "\n",
        "# TODO: Create the trainer\n",
        "trainer = None  # Replace None with your code\n",
        "\n",
        "print(\"Trainer created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xejdr6UO-q2c"
      },
      "source": [
        "## Step 8: Train the Model\n",
        "\n",
        "Now let's fine-tune! This will take several minutes depending on your GPU.\n",
        "\n",
        "**TODO**: Start the training process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QFqibL8-q2c"
      },
      "outputs": [],
      "source": [
        "print(\"Starting fine-tuning...\\n\")\n",
        "print(\"=\" * 80)\n",
        "print(\"This will train for 4 epochs and evaluate after each epoch.\")\n",
        "print(\"The model will be optimized for dimension 128.\")\n",
        "print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "# TODO: Train the model\n",
        "# Replace pass with your code\n",
        "pass\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Training complete!\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31W4oVsh-q2c"
      },
      "source": [
        "## Step 9: Save the Fine-Tuned Model\n",
        "\n",
        "**TODO**: Save the model for future use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UetrdVFd-q2c"
      },
      "outputs": [],
      "source": [
        "print(\"Saving fine-tuned model...\")\n",
        "\n",
        "# TODO: Save the model\n",
        "# Replace pass with your code\n",
        "pass\n",
        "\n",
        "print(f\"Model saved to {OUTPUT_DIR}!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btIkxQPv-q2c"
      },
      "source": [
        "## Step 10: Evaluate Fine-Tuned Model\n",
        "\n",
        "Let's evaluate our fine-tuned model and compare it to the baseline!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7vhgGcW-q2c"
      },
      "source": [
        "### 10.1: Load and Evaluate Fine-Tuned Model\n",
        "\n",
        "**TODO**: Load the fine-tuned model and evaluate it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7MDFP0I-q2c"
      },
      "outputs": [],
      "source": [
        "print(\"Evaluating fine-tuned model...\\n\")\n",
        "print(\"This may take a few minutes...\\n\")\n",
        "\n",
        "# TODO: Load the fine-tuned model\n",
        "fine_tuned_model = None  # Replace None with your code\n",
        "\n",
        "# TODO: Evaluate the fine-tuned model\n",
        "results = None  # Replace None with your code\n",
        "\n",
        "print(\"\\nFine-tuned model evaluation complete!\\n\")\n",
        "print(\"Fine-tuned NDCG@10 scores by dimension:\\n\")\n",
        "\n",
        "# Print NDCG@10 scores for each dimension\n",
        "finetuned_scores = {}\n",
        "for dim in MATRYOSHKA_DIMENSIONS:\n",
        "    key = f\"dim_{dim}_cosine_ndcg@10\"\n",
        "    score = results[key]\n",
        "    finetuned_scores[dim] = score\n",
        "    print(f\"   dim {dim}: {score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI5cTcfL-q2h"
      },
      "source": [
        "### 10.2: Compare Results\n",
        "\n",
        "Let's create a comparison table to see the improvement!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuqPS3QT-q2h"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create comparison DataFrame\n",
        "comparison_data = []\n",
        "for dim in MATRYOSHKA_DIMENSIONS:\n",
        "    baseline = baseline_scores[dim]\n",
        "    finetuned = finetuned_scores[dim]\n",
        "    improvement = ((finetuned - baseline) / baseline) * 100\n",
        "\n",
        "    comparison_data.append({\n",
        "        'Dimension': dim,\n",
        "        'Baseline': f\"{baseline:.4f}\",\n",
        "        'Fine-tuned': f\"{finetuned:.4f}\",\n",
        "        'Improvement': f\"{improvement:.2f}%\"\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PERFORMANCE COMPARISON\")\n",
        "print(\"=\" * 80)\n",
        "print(comparison_df.to_string(index=False))\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OllyMZEt-q2h"
      },
      "source": [
        "### 10.3: Analyze Results\n",
        "\n",
        "Let's analyze the key findings from our fine-tuning experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPUjrDrQ-q2h"
      },
      "outputs": [],
      "source": [
        "print(\"\\nKEY INSIGHTS:\\n\")\n",
        "\n",
        "# Calculate storage reduction at 128 dimensions\n",
        "storage_reduction = 768 / 128\n",
        "performance_retention_128 = (finetuned_scores[128] / finetuned_scores[768]) * 100\n",
        "\n",
        "# Best improvement dimension\n",
        "best_improvement_dim = max(MATRYOSHKA_DIMENSIONS,\n",
        "                           key=lambda d: (finetuned_scores[d] - baseline_scores[d]) / baseline_scores[d])\n",
        "best_improvement = ((finetuned_scores[best_improvement_dim] - baseline_scores[best_improvement_dim]) /\n",
        "                   baseline_scores[best_improvement_dim]) * 100\n",
        "\n",
        "print(f\"1. Average improvement across all dimensions: \"\n",
        "      f\"{sum((finetuned_scores[d] - baseline_scores[d]) / baseline_scores[d] for d in MATRYOSHKA_DIMENSIONS) / len(MATRYOSHKA_DIMENSIONS) * 100:.2f}%\")\n",
        "\n",
        "print(f\"\\n2. Largest improvement: {best_improvement:.2f}% at dimension {best_improvement_dim}\")\n",
        "\n",
        "print(f\"\\n3. Dimension 128 achieves {performance_retention_128:.2f}% of full 768-dim performance\")\n",
        "print(f\"   with {storage_reduction:.0f}x storage reduction!\")\n",
        "\n",
        "print(f\"\\n4. Fine-tuned 128-dim vs Baseline 768-dim:\")\n",
        "cross_comparison = ((finetuned_scores[128] - baseline_scores[768]) / baseline_scores[768]) * 100\n",
        "print(f\"   Fine-tuned 128-dim is {cross_comparison:+.2f}% vs baseline 768-dim\")\n",
        "print(f\"   (Smaller, faster, AND better!)\")\n",
        "\n",
        "print(f\"\\n5. Fine-tuned 64-dim vs Baseline 768-dim:\")\n",
        "cross_comparison_64 = ((finetuned_scores[64] - baseline_scores[768]) / baseline_scores[768]) * 100\n",
        "print(f\"   Fine-tuned 64-dim is {cross_comparison_64:+.2f}% vs baseline 768-dim\")\n",
        "print(f\"   (12x smaller!)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3LKxPBo-q2h"
      },
      "source": [
        "## Step 11: Test with Sample Queries\n",
        "\n",
        "Let's test our fine-tuned model with some sample financial questions!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYfWnqZt-q2h"
      },
      "outputs": [],
      "source": [
        "# Sample queries to test\n",
        "sample_queries = [\n",
        "    \"What was NVIDIA's total revenue?\",\n",
        "    \"What are the main business segments?\",\n",
        "    \"What are the key risk factors?\"\n",
        "]\n",
        "\n",
        "print(\"Testing retrieval with sample queries:\\n\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for query in sample_queries:\n",
        "    print(f\"\\nQuery: {query}\\n\")\n",
        "\n",
        "    # Encode query with fine-tuned model (using 128 dimensions)\n",
        "    query_embedding = fine_tuned_model.encode(query, convert_to_tensor=True)\n",
        "    query_embedding = query_embedding[:128]  # Truncate to 128 dimensions\n",
        "\n",
        "    # Encode all corpus documents\n",
        "    corpus_embeddings = fine_tuned_model.encode(list(corpus.values()), convert_to_tensor=True)\n",
        "    corpus_embeddings = corpus_embeddings[:, :128]  # Truncate to 128 dimensions\n",
        "\n",
        "    # Calculate similarity scores\n",
        "    scores = cos_sim(query_embedding, corpus_embeddings)[0]\n",
        "\n",
        "    # Get top result\n",
        "    top_idx = scores.argmax().item()\n",
        "    top_doc_id = list(corpus.keys())[top_idx]\n",
        "    top_doc = corpus[top_doc_id]\n",
        "\n",
        "    print(f\"Top Retrieved Document (score: {scores[top_idx]:.4f}):\")\n",
        "    print(f\"{top_doc[:300]}...\")\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQxVYhkF-q2i"
      },
      "source": [
        "## Congratulations!\n",
        "\n",
        "You've successfully fine-tuned an embedding model with Matryoshka representation learning! Here's what you accomplished:\n",
        "\n",
        "1. ✅ Loaded and prepared a domain-specific Q&A dataset\n",
        "2. ✅ Established a baseline with pre-trained embeddings\n",
        "3. ✅ Implemented Matryoshka Representation Learning\n",
        "4. ✅ Fine-tuned an embedding model with MultipleNegativesRankingLoss\n",
        "5. ✅ Evaluated performance across multiple embedding dimensions\n",
        "6. ✅ Achieved significant improvements (typically 7-22% boost)\n",
        "7. ✅ Demonstrated 6x storage reduction with maintained performance\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "**Why This Matters:**\n",
        "- Fine-tuning embedding models is crucial for domain-specific RAG applications\n",
        "- Matryoshka embeddings provide flexibility in the speed/accuracy trade-off\n",
        "- Even small datasets (6-7k samples) can yield significant improvements\n",
        "- Smaller dimensions can outperform larger baseline dimensions after fine-tuning\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "Want to go further? Try:\n",
        "- Fine-tuning on your own domain-specific data\n",
        "- Experimenting with different base models (e.g., bge-large, e5-base)\n",
        "- Testing different Matryoshka dimension combinations\n",
        "- Trying other loss functions (CosineSimilarityLoss, ContrastiveLoss)\n",
        "- Generating synthetic training data using LLMs\n",
        "- Integrating the fine-tuned model into a full RAG pipeline\n",
        "- Benchmarking inference speed across different dimensions\n",
        "\n",
        "### Additional Resources\n",
        "\n",
        "- [Sentence Transformers Documentation](https://sbert.net/)\n",
        "- [Matryoshka Representation Learning Paper](https://arxiv.org/abs/2205.13147)\n",
        "- [BGE Embedding Models](https://huggingface.co/BAAI/bge-base-en-v1.5)\n",
        "- [Information Retrieval Evaluation](https://sbert.net/docs/package_reference/sentence_transformer/evaluation.html)\n",
        "\n",
        "### Real-World Applications\n",
        "\n",
        "This technique is used in production for:\n",
        "- **Customer support**: Domain-specific FAQ retrieval\n",
        "- **Legal tech**: Case law and document search\n",
        "- **Healthcare**: Medical literature retrieval\n",
        "- **E-commerce**: Product search and recommendations\n",
        "- **Finance**: Regulatory document search (like we did!)\n",
        "\n",
        "Great work!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}